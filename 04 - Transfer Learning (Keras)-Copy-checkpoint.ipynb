{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Using Transfer Learning to Train a CNN\n\nFirst, we'll import the latest version of Keras and prepare to load our training data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install --upgrade keras\n\nimport keras\nfrom keras import backend as K\n\nprint('Keras version:',keras.__version__)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Prepare the Data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# The images are in a folder named 'classification/training'\ntraining_folder_name = '../data/classification/training'\n\n# The folder contains a subfolder for each class of shape\nclasses = sorted(os.listdir(training_folder_name))\nprint(classes)\n\n# Our source images are 128x128, but the base model we're going to use was trained with 224x224 images\npretrained_size = (224,224)\nbatch_size = 15\n\nprint(\"Getting Data...\")\ndatagen = ImageDataGenerator(rescale=1./255, # normalize pixel values\n                             validation_split=0.3) # hold back 30% of the images for validation\n\nprint(\"Preparing training dataset...\")\ntrain_generator = datagen.flow_from_directory(\n    training_folder_name,\n    target_size=pretrained_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nprint(\"Preparing validation dataset...\")\nvalidation_generator = datagen.flow_from_directory(\n    training_folder_name,\n    target_size=pretrained_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation') # set as validation data\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Download a trained model to use as a base"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras import applications\n#Load the base model, not including its final connected layer, and set the input shape to match our images\nbase_model = keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=train_generator.image_shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Freeze the already trained layers and add a custom output layer for our classes"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras import Model\nfrom keras.layers import Flatten, Dense\nfrom keras import optimizers\n\n# Freeze the already-trained layers in the base model\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Create layers for classification of our images\nx = base_model.output\nx = Flatten()(x)\nprediction_layer = Dense(len(classes), activation='sigmoid')(x) \nmodel = Model(inputs=base_model.input, outputs=prediction_layer)\n\n# Compile the model\nopt = optimizers.Adam(lr=0.001)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\n\n# Now print the full model, which will include the layers of the base model plus the dense layer we added\nprint(model.summary())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Train the Model"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Train the model over 2 epochs using 15-image batches and using the validation holdout dataset for validation\nnum_epochs = 2\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples // batch_size,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples // batch_size,\n    epochs = num_epochs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Using the Trained Model\nNow that we've trained the model, we can use it to predict the class of an image."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Helper function to resize image\ndef resize_image(src_img, size=(128,128), bg_color=\"white\"): \n    from PIL import Image\n\n    # rescale the image so the longest edge is the right size\n    src_img.thumbnail(size, Image.ANTIALIAS)\n    \n    # Create a new image of the right shape\n    new_image = Image.new(\"RGB\", size, bg_color)\n    \n    # Paste the rescaled image onto the new background\n    new_image.paste(src_img, (int((size[0] - src_img.size[0]) / 2), int((size[1] - src_img.size[1]) / 2)))\n  \n    # return the resized image\n    return new_image\n\n# Function to predict the class of an image\ndef predict_image(classifier, image_array):\n    import numpy as np\n    \n    # We need to format the input to match the training data\n    # The data generator loaded the values as floating point numbers\n    # and normalized the pixel values, so...\n    img_features = image_array.astype('float32')\n    img_features /= 255\n    \n    # These are the classes our model can predict\n    classnames = ['automobile', 'plane', 'train']\n    \n    # Predict the class of each input image\n    predictions = classifier.predict(img_features)\n    \n    predicted_classes = []\n    for prediction in predictions:\n        # The prediction for each image is the probability for each class, e.g. [0.8, 0.1, 0.2]\n        # So get the index of the highest probability\n        class_idx = np.argmax(prediction)\n        # And append the corresponding class name to the results\n        predicted_classes.append(classnames[int(class_idx)])\n    # Return the predictions\n    return predicted_classes\n\nprint(\"Functions created - ready to use model for inference.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nfrom random import randint\nimport numpy as np\nfrom PIL import Image\nfrom keras.models import load_model\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n#get the list of test image files\ntest_folder = '../data/classification/test'\ntest_image_files = os.listdir(test_folder)\n\n# Empty array on which to store the images\nimage_arrays = []\n\nsize = (224,224)\nbackground_color=\"white\"\n\nfig = plt.figure(figsize=(12, 8))\n\n# Get the images and show the predicted classes\nfor file_idx in range(len(test_image_files)):\n    img = Image.open(os.path.join(test_folder, test_image_files[file_idx]))\n    \n    # resize the image so it matches the training set - it  must be the same size as the images on which the model was trained\n    resized_img = np.array(resize_image(img, size, background_color))\n                      \n    # Add the image to the array of images\n    image_arrays.append(resized_img)\n\n# Get predictions from the array of image arrays\n# Note that the model expects an array of 1 or more images - just like the batches on which it was trained\npredictions = predict_image(model, np.array(image_arrays))\n\n# plot easch image with its corresponding prediction\nfor idx in range(len(predictions)):\n    a=fig.add_subplot(1,len(predictions),idx+1)\n    imgplot = plt.imshow(image_arrays[idx])\n    a.set_title(predictions[idx])\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}